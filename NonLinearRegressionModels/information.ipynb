{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b24eec-100d-405d-bcb4-c087d7cd0a21",
   "metadata": {},
   "source": [
    "### Doğrusal Olmayan Regresyon Modelleri Karşılaştırma Tablosu\n",
    "\n",
    "| Model Adı                    | Temel Prensip                                       | Güçlü Yönleri                                                                                                                               | Zayıf Yönleri / Dikkat Edilmesi Gerekenler                                                                                                  | Ne Zaman Kullanılmalı? (Senaryolar)                                                                                                                            | Temel Özellikler / Önemli Parametreler                                                                                               | Doğrusal Olmayan İlişkileri Yakalama |\n",
    "| :--------------------------- | :-------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------ | :---------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------- |\n",
    "| **Yapay Sinir Ağları (ANN)** | Nöronlardan oluşan katmanlı yapı, ağırlık optimizasyonu | Çok karmaşık ve yüksek boyutlu doğrusal olmayan ilişkileri modelleyebilir, örtük özellik çıkarımı yapabilir.                               | Hesaplama maliyeti yüksek, çok fazla veri gerektirir, aşırı öğrenmeye (overfitting) eğilimli, \"kara kutu\" (yorumlanabilirliği düşük), hiperparametre ayarı zor. | Çok büyük veri setleri, görüntü/ses/metin gibi yapısal olmayan veriler, karmaşıklığın yüksek olduğu ve yorumlanabilirliğin ikinci planda olduğu problemler. | Özellik ölçeklendirme şart, katman sayısı, nöron sayısı, aktivasyon fonksiyonları, optimizasyon algoritması, öğrenme oranı.            | Mükemmel                             |\n",
    "| **CART (Karar Ağacı Regresyonu)** | Veriyi reküristif olarak alt kümelere bölen tek ağaç | Anlaması ve yorumlaması kolay, görselleştirilebilir, sayısal ve kategorik veriyi işleyebilir, az veri ön işleme gerektirir (ölçeklendirme şart değil). | Aşırı öğrenmeye çok eğilimli, verideki küçük değişikliklere duyarlı (kararsız), yumuşak doğrusal ilişkileri yakalamada zayıf kalabilir.            | Hızlı bir başlangıç modeli olarak, yorumlanabilirliğin önemli olduğu durumlar, küçük-orta ölçekli veri setleri.                                            | `max_depth`, `min_samples_split`, `min_samples_leaf` gibi budama parametreleri önemli.                                                 | İyi (parçalı sabit tahminler)        |\n",
    "| **CatBoost** | Gradyan Artırma (Gradient Boosting) ağaç topluluğu    | Yüksek performans, kategorik özellikleri otomatik ve etkili işler (ordered boosting), diğer GBT'lere göre aşırı öğrenmeye daha dirençli, varsayılan parametrelerle iyi sonuçlar. | Bazı veri setlerinde LightGBM'den yavaş olabilir, XGBoost/LightGBM kadar yaygın olmasa da popülaritesi artıyor.                               | Özellikle çok sayıda kategorik özellik içeren veri setleri, yüksek doğruluk hedeflendiğinde, az hiperparametre ayarıyla hızlı sonuç istenildiğinde.          | Kategorik özellik yönetimi çok iyi, `iterations`, `learning_rate`, `depth`.                                                        | Mükemmel                             |\n",
    "| **K-En Yakın Komşu (KNN) Regresyonu** | Tahmin için en yakın komşuların ortalamasını alır      | Anlaması basit, eğitim aşaması yok (veriyi saklar), yerel örüntüleri bulmada iyi.                                                           | Tahmin aşaması hesaplama açısından pahalı (özellikle büyük verilerde), K değeri ve uzaklık metriğine çok duyarlı, özellik ölçeklendirme şart, yüksek boyutlulukta performansı düşer. | Küçük veri setleri, veride yerel bir yapı olduğunda, basit bir başlangıç modeli gerektiğinde.                                                              | Özellik ölçeklendirme şart, K değeri kritik, `weights` (uniform, distance).                                                          | İyi (yerel doğrusal olmayanlıklar) |\n",
    "| **LightGBM** | Gradyan Artırma (Gradient Boosting) ağaç topluluğu    | Çok hızlı eğitim, bellek verimliliği yüksek (histogram tabanlı), mükemmel doğruluk, büyük veri setlerini işleyebilir, GPU desteği.        | Küçük veri setlerinde dikkatli ayar yapılmazsa aşırı öğrenebilir, hiperparametrelere duyarlı olabilir.                                       | Büyük veri setleri, eğitim hızının kritik olduğu durumlar, yüksek doğruluk gereksinimleri.                                                                  | Hızlı ve verimli, `num_leaves`, `learning_rate`, `n_estimators`, `min_child_samples`. Özellikle küçük verilerde dikkatli ayar ister. | Mükemmel                             |\n",
    "| **Random Forest (Rastgele Orman) Regresyonu** | Çok sayıda karar ağacının torbalama (bagging) ile birleşimi | İyi doğruluk, tek ağaca göre aşırı öğrenmeye daha dirençli, yüksek boyutluluk ve büyük veri setlerini işleyebilir, özellik önemini verir.       | Çok fazla ağaçla hesaplama maliyeti artabilir, tek ağaç kadar yorumlanabilir değil, eğitim verisinin dışındaki değerler için tahmin yapmada zorlanır. | Genel amaçlı iyi bir algoritma, sağlam ve görece kolay ayarlanabilen bir model gerektiğinde, özellik öneminin istendiği durumlar.                        | `n_estimators`, `max_features`, `max_depth`, `min_samples_split`. Aşırı öğrenmeye tek ağaçtan daha dirençli.                          | Mükemmel                             |\n",
    "| **Destek Vektör Regresyonu (SVR)** | Veri noktalarını ayıran hiper-düzlemi ve marjini kullanır | Yüksek boyutlu uzaylarda etkili, bellek verimli (destek vektörlerini kullanır), farklı çekirdek (kernel) fonksiyonları ile esneklik sağlar. | Çok büyük veri setlerinde eğitimi yavaş olabilir, performansı çekirdek ve parametrelerine (C, gamma, epsilon) çok bağlı, özellik ölçeklendirme şart. | Yüksek boyutlu veriler, ilişkinin aşırı karmaşık olmadığı veya belirli çekirdek varsayımlarının veriye uyduğu durumlar, orta ölçekli veri setleri.         | Özellik ölçeklendirme şart, Çekirdek (`linear`, `poly`, `rbf`) ve `C`, `gamma`, `epsilon` parametreleri kritik.                        | İyi (çekirdeğe bağlı)                |\n",
    "| **XGBoost** | Gradyan Artırma (Gradient Boosting) ağaç topluluğu    | Mükemmel performans (genellikle en iyi), yüksek optimizasyon, aşırı öğrenmeyi engelleyen regülarizasyon, eksik verileri işleyebilir, GPU desteği. | Random Forest'a göre ayarlanması daha karmaşık olabilir, küçük veri setlerinde dikkatli ayar yapılmazsa aşırı öğrenebilir.                       | Yapısal/tablosal veriler için yarışmalarda ve endüstride yaygın, en yüksek doğruluk hedeflendiğinde.                                                      | Regülarizasyon (`lambda`, `alpha`), eksik veri yönetimi, `n_estimators`, `learning_rate`, `max_depth`.                                   | Mükemmel                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f7bce-e9a7-41f9-ace1-01683ac1f153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
